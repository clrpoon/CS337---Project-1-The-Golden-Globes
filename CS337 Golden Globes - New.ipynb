{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\casey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\casey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\casey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\casey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import operator\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "import time\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cache all tweets in global dictionary ALL_TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading gg2013.json start time 20:11:10\n",
      "loading gg2013.json end time 20:11:11\n",
      "time elapsed 0:00:00\n",
      "loading gg2015.json start time 20:11:11\n",
      "loading gg2015.json end time 20:11:20\n",
      "time elapsed 0:00:08\n",
      "loading gg2020.json start time 20:11:20\n",
      "could not read json in the form of dictionary list\n",
      "trying jsonl reading instead\n",
      "loading gg2020.json end time 20:11:21\n",
      "time elapsed 0:00:01\n",
      "total time elapsed 11.06644868850708\n",
      "Pre-ceremony processing complete.\n"
     ]
    }
   ],
   "source": [
    "ALL_TWEETS = {}\n",
    "\n",
    "path_to_dataset = \"../gg-datasets/\"\n",
    "def convert(seconds): \n",
    "    seconds = seconds % (24 * 3600) \n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "      \n",
    "    return \"%d:%02d:%02d\" % (hour, minutes, seconds)\n",
    "\n",
    "\n",
    "def get_tweets(year):\n",
    "    if year in ALL_TWEETS:\n",
    "        return ALL_TWEETS[year]\n",
    "    else:\n",
    "        try:\n",
    "            file = open(path_to_dataset+'gg'+str(year)+'.json', encoding = 'utf8')\n",
    "            data = json.load(file)\n",
    "\n",
    "            ALL_TWEETS[year] = [line['text'] for line in data]\n",
    "            return ALL_TWEETS[year]\n",
    "        except:\n",
    "            print('could not read json in the form of dictionary list')\n",
    "            print('trying jsonl reading instead')\n",
    "        try:\n",
    "            with open(path_to_dataset+'gg'+str(year)+'.json', encoding='utf8') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            gg_data = []\n",
    "            for line in lines:\n",
    "                gg_data.append(json.loads(line)['text'])\n",
    "\n",
    "            ALL_TWEETS[year] = gg_data\n",
    "            return ALL_TWEETS[year]\n",
    "        except:\n",
    "            print('could not read json as jsonl')\n",
    "            print('check json format')\n",
    "            print('get_tweets returned []')\n",
    "        return []\n",
    "\n",
    "\n",
    "def load_all():\n",
    "    init_time = time.time()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print('loading gg2013.json start time', convert(start_time))\n",
    "    get_tweets(2013)\n",
    "    end_time = time.time()\n",
    "    print('loading gg2013.json end time', convert(end_time))\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('time elapsed', convert(elapsed_time))\n",
    " \n",
    "    \n",
    "    start_time = time.time()\n",
    "    print('loading gg2015.json start time', convert(start_time))\n",
    "    get_tweets(2015)\n",
    "    end_time = time.time()\n",
    "    print('loading gg2015.json end time', convert(end_time))\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('time elapsed', convert(elapsed_time))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print('loading gg2020.json start time', convert(start_time))\n",
    "    get_tweets(2020)\n",
    "    end_time = time.time()\n",
    "    print('loading gg2020.json end time', convert(end_time))\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('time elapsed', convert(elapsed_time))\n",
    "    \n",
    "    print('total time elapsed', time.time() - init_time)\n",
    "    \n",
    "def pre_ceremony():\n",
    "    '''This function loads/fetches/processes any data your program\n",
    "    will use, and stores that data in your DB or in a json, csv, or\n",
    "    plain text file. It is the first thing the TA will run when grading.\n",
    "    Do NOT change the name of this function or what it returns.'''\n",
    "    # Your code here\n",
    "    load_all()\n",
    "    print(\"Pre-ceremony processing complete.\")\n",
    "    return\n",
    "\n",
    "pre_ceremony()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "OFFICIAL_AWARDS_1315 = ['cecil b. demille award', 'best motion picture - drama', 'best performance by an actress in a motion picture - drama', 'best performance by an actor in a motion picture - drama', 'best motion picture - comedy or musical', 'best performance by an actress in a motion picture - comedy or musical', 'best performance by an actor in a motion picture - comedy or musical', 'best animated feature film', 'best foreign language film', 'best performance by an actress in a supporting role in a motion picture', 'best performance by an actor in a supporting role in a motion picture', 'best director - motion picture', 'best screenplay - motion picture', 'best original score - motion picture', 'best original song - motion picture', 'best television series - drama', 'best performance by an actress in a television series - drama', 'best performance by an actor in a television series - drama', 'best television series - comedy or musical', 'best performance by an actress in a television series - comedy or musical', 'best performance by an actor in a television series - comedy or musical', 'best mini-series or motion picture made for television', 'best performance by an actress in a mini-series or motion picture made for television', 'best performance by an actor in a mini-series or motion picture made for television', 'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television', 'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television']\n",
    "OFFICIAL_AWARDS_1819 = ['best motion picture - drama', 'best motion picture - musical or comedy', 'best performance by an actress in a motion picture - drama', 'best performance by an actor in a motion picture - drama', 'best performance by an actress in a motion picture - musical or comedy', 'best performance by an actor in a motion picture - musical or comedy', 'best performance by an actress in a supporting role in any motion picture', 'best performance by an actor in a supporting role in any motion picture', 'best director - motion picture', 'best screenplay - motion picture', 'best motion picture - animated', 'best motion picture - foreign language', 'best original score - motion picture', 'best original song - motion picture', 'best television series - drama', 'best television series - musical or comedy', 'best television limited series or motion picture made for television', 'best performance by an actress in a limited series or a motion picture made for television', 'best performance by an actor in a limited series or a motion picture made for television', 'best performance by an actress in a television series - drama', 'best performance by an actor in a television series - drama', 'best performance by an actress in a television series - musical or comedy', 'best performance by an actor in a television series - musical or comedy', 'best performance by an actress in a supporting role in a series, limited series or motion picture made for television', 'best performance by an actor in a supporting role in a series, limited series or motion picture made for television', 'cecil b. demille award']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = \"../gg-datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(text):\n",
    "    \"\"\"\n",
    "    Gets NER from sentence using NLTK\n",
    "    \"\"\"\n",
    "    article = nlp(text)\n",
    "    labels = [x.label_ for x in article.ents]\n",
    "    [(x.orth_,x.pos_, x.lemma_) for x in [y \n",
    "                                      for y\n",
    "                                      in nlp(text) \n",
    "                                      if not y.is_stop and y.pos_ != 'PUNCT']]\n",
    "    parts_of_speech = dict([(str(x), x.label_) for x in nlp(text).ents])\n",
    "    names = []\n",
    "    for (key, value) in parts_of_speech.items() :\n",
    "        if(value == \"PERSON\") :\n",
    "            names.append(key)\n",
    "    return names \n",
    "\n",
    "def get_hosts(year):\n",
    "    '''Hosts is a list of one or more strings. Do NOT change the name\n",
    "    of this function or what it returns.'''\n",
    "    # Your code here\n",
    "    \n",
    "    # Load dataset from that year\n",
    "    filename = path_to_dataset+'gg'+str(year)+'.json'\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf8') as f:\n",
    "        gg_data = json.loads(f.read())\n",
    "        print(\"json from \"+ str(year)+\" done loading\")\n",
    "        \n",
    "    # Get tweets with keyword 'host'\n",
    "        tweets_with_host = []\n",
    "        for tweet in gg_data: \n",
    "            tweet_text = tweet['text']\n",
    "            if(\"host\" in tweet_text.lower()) :\n",
    "                tweets_with_host.append(tweet)\n",
    "        print(\"done filtering for keyword host\")\n",
    "        \n",
    "        host_name_count = {}\n",
    "        \n",
    "        for tweet in tweets_with_host: \n",
    "            names = get_names(tweet[\"text\"])\n",
    "            for name in names :\n",
    "                if name.lower() in [\"goldenglobes\", \"goldenglobe\", \"golden\", \"globes\", \"golden globes\", \"golden globe\"]:\n",
    "                    continue\n",
    "                if name in host_name_count :\n",
    "                    host_name_count[name] = host_name_count[name] + 1\n",
    "                else:\n",
    "                    host_name_count[name] = 1\n",
    "        print(\"done applying bag of words on NER\")\n",
    "        max_count_name = max(host_name_count.items(), key=operator.itemgetter(1))[0]\n",
    "        \n",
    "        \n",
    "\n",
    "#         if year >= 2013 and year <= 2015 or year == 2019:\n",
    "#             hosts = potential_hosts[:1]\n",
    "#         else: #one host\n",
    "#             hosts = max(host_name_count.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "        return max_count_name, gg_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json from 2013 done loading\n",
      "done filtering for keyword host\n",
      "done applying bag of words on NER\n"
     ]
    }
   ],
   "source": [
    "mcn,data = get_hosts(2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will Ferrell\n"
     ]
    }
   ],
   "source": [
    "print(mcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_awards(year):\n",
    "    '''Awards is a list of strings. Do NOT change the name\n",
    "    of this function or what it returns.'''\n",
    "    # Your code here\n",
    "    return awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nominees(year):\n",
    "    '''Nominees is a dictionary with the hard coded award\n",
    "    names as keys, and each entry a list of strings. Do NOT change\n",
    "    the name of this function or what it returns.'''\n",
    "    # Your code here\n",
    "    return nominees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winner(year):\n",
    "    '''Winners is a dictionary with the hard coded award\n",
    "    names as keys, and each entry containing a single string.\n",
    "    Do NOT change the name of this function or what it returns.'''\n",
    "    # Your code here\n",
    "    return winners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_presenters(year):\n",
    "    '''Presenters is a dictionary with the hard coded award\n",
    "    names as keys, and each entry a list of strings. Do NOT change the\n",
    "    name of this function or what it returns.'''\n",
    "    # Your code here\n",
    "    return presenters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_ceremony():\n",
    "    '''This function loads/fetches/processes any data your program\n",
    "    will use, and stores that data in your DB or in a json, csv, or\n",
    "    plain text file. It is the first thing the TA will run when grading.\n",
    "    Do NOT change the name of this function or what it returns.'''\n",
    "    # Your code here\n",
    "    print(\"Pre-ceremony processing complete.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(text):\n",
    "    \"\"\"\n",
    "    Gets NER from sentence using NLTK\n",
    "    \"\"\"\n",
    "    article = nlp(text)\n",
    "    labels = [x.label_ for x in article.ents]\n",
    "    [(x.orth_,x.pos_, x.lemma_) for x in [y \n",
    "                                      for y\n",
    "                                      in nlp(text) \n",
    "                                      if not y.is_stop and y.pos_ != 'PUNCT']]\n",
    "    parts_of_speech = dict([(str(x), x.label_) for x in nlp(text).ents])\n",
    "    names = []\n",
    "    for (key, value) in parts_of_speech.items() :\n",
    "        if(value == \"PERSON\") :\n",
    "            names.append(key)\n",
    "    return names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by(tweets, )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
